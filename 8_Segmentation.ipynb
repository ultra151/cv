{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR7s/5P2Y0XtMpp0Wiiech",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ultra151/cv/blob/main/8_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOPGSxuwpcn1"
      },
      "outputs": [],
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz"
      ],
      "metadata": {
        "id": "s_gj8pW4tvjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "print(\"Current working directory:\", current_dir)"
      ],
      "metadata": {
        "id": "hetgt5WNtzrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "K4ybO13ltznz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"images\"))"
      ],
      "metadata": {
        "id": "Qbl2GRQMtzkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TOE0l8QatzgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotation_file = 'annotations/trimaps/Abyssinian_1.png'\n",
        "annotation_image = Image.open(annotation_file)\n",
        "annotation_array = np.array(annotation_image)\n",
        "\n",
        "unique_values = np.unique(annotation_array)\n",
        "print(\"Unique values in the annotation image:\", unique_values)"
      ],
      "metadata": {
        "id": "dJ4D_fOetzYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(annotation_array, cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C1Gs1EeTJGuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
        "#print(annotation_array)"
      ],
      "metadata": {
        "id": "HWXfO6OVKNO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "img_size = (160, 160)\n",
        "num_classes = 3\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "zoeIOXExLLqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir, fname)\n",
        "        for fname in os.listdir(target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "2-sQdYABNPsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_paths[:3]"
      ],
      "metadata": {
        "id": "gmDpLSn7QVGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"입력 샘플의 수:\", len(input_img_paths))\n",
        "print(\"타겟 샘플의 수:\", len(target_img_paths))"
      ],
      "metadata": {
        "id": "co8JFPvYPrJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from keras.utils import load_img\n",
        "from PIL import ImageOps\n",
        "\n",
        "display(Image(filename=input_img_paths[9]))\n",
        "\n",
        "img = ImageOps.autocontrast(load_img(target_img_paths[9]))\n",
        "display(img)"
      ],
      "metadata": {
        "id": "jP0ENzB_QPc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n"
      ],
      "metadata": {
        "id": "hNFwKbvlRDzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size, img_size, input_img_paths, target_img_paths, max_dataset_len=None):\n",
        "\n",
        "    def load_img_masks(input_img_path, target_img_path):\n",
        "        input_img = tf_io.read_file(input_img_path)\n",
        "        input_img = tf_io.decode_jpeg(input_img, channels=3)\n",
        "        input_img = tf_image.resize(input_img, img_size)\n",
        "        input_img = tf_image.convert_image_dtype(input_img, \"float32\")\n",
        "\n",
        "        target_img = tf_io.read_file(target_img_path)\n",
        "        target_img = tf_io.decode_png(target_img, channels=1)\n",
        "        target_img = tf_image.resize(target_img, img_size, method=\"nearest\")\n",
        "        target_img = tf_image.convert_image_dtype(target_img, \"uint8\")\n",
        "\n",
        "        target_img -= 1\n",
        "        return input_img, target_img\n",
        "\n",
        "    if max_dataset_len:\n",
        "        input_img_paths = input_img_paths[:max_dataset_len]\n",
        "        target_img_paths = target_img_paths[:max_dataset_len]\n",
        "\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((input_img_paths, target_img_paths))\n",
        "    dataset = dataset.map(load_img_masks, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "    return dataset.batch(batch_size)\n"
      ],
      "metadata": {
        "id": "7_3_EfWbVHCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([1,2,3,4,5])\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "print(type(dataset))\n",
        "\n",
        "for element in dataset:\n",
        "    print(element.numpy())"
      ],
      "metadata": {
        "id": "IOVbx1Voakfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "B-UxX9LTeaTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(img_size, num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "92m6aVnUpLJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
      ],
      "metadata": {
        "id": "eTbwu4olpQvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "val_samples = 1000\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_img_paths)\n",
        "\n",
        "train_input_img_paths = input_img_paths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "\n",
        "val_input_img_paths = input_img_paths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "train_dataset = get_dataset(batch_size, img_size, train_input_img_paths, train_target_img_paths, max_dataset_len=1000)\n",
        "valid_dataset = get_dataset(batch_size, img_size, val_input_img_paths, val_target_img_paths)"
      ],
      "metadata": {
        "id": "3UOSx1wiplYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\")\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\", save_best_only=True)]\n",
        "\n",
        "epochs = 50\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "-Th3mM7Hze39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = get_dataset(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
        "val_preds = model.predict(val_dataset)\n",
        "\n",
        "print(val_preds[0])"
      ],
      "metadata": {
        "id": "OlB8uuBjOviB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_preds.shape)"
      ],
      "metadata": {
        "id": "3h9C_YSqXC0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_mask(i):\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = ImageOps.autocontrast(keras.utils.array_to_img(mask))\n",
        "    display(img)"
      ],
      "metadata": {
        "id": "sPdiWy7zXimc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10\n",
        "display(Image(filename=val_input_img_paths[i]))\n",
        "\n",
        "img = ImageOps.autocontrast(load_img(val_target_img_paths[i]))\n",
        "display(img)\n",
        "\n",
        "display_mask(i)"
      ],
      "metadata": {
        "id": "rBr0CLX4YUt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = np.argmax(val_preds[10], axis=-1)\n",
        "mask_positions = np.where(predicted_classes == 0)\n",
        "print(\"경계 픽셀의 (행, 열) 포지션:\", mask_positions)"
      ],
      "metadata": {
        "id": "0qz4uphzZH4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mask_positions[0][0])\n",
        "print(mask_positions[1][0])"
      ],
      "metadata": {
        "id": "LjMcsNbUaxVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rQVP0Rga3O6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}